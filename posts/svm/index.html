<!DOCTYPE html><html lang="en" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="prefer-datetime-locale" content="en-nz"><meta name="generator" content="Jekyll v4.2.2" /><meta property="og:title" content="Support Vector Machines" /><meta property="og:locale" content="en" /><meta name="description" content="In this assignment for a machine learning course, I generate synthetic data and explore how the underlying patterns affect SVM tuning parameters." /><meta property="og:description" content="In this assignment for a machine learning course, I generate synthetic data and explore how the underlying patterns affect SVM tuning parameters." /><link rel="canonical" href="https://chaserobertson.github.io/posts/svm/" /><meta property="og:url" content="https://chaserobertson.github.io/posts/svm/" /><meta property="og:site_name" content="Chase Robertson" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2022-06-20T00:00:00+12:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="Support Vector Machines" /><meta name="twitter:site" content="@chase__rob" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2022-06-20T00:00:00+12:00","datePublished":"2022-06-20T00:00:00+12:00","description":"In this assignment for a machine learning course, I generate synthetic data and explore how the underlying patterns affect SVM tuning parameters.","headline":"Support Vector Machines","mainEntityOfPage":{"@type":"WebPage","@id":"https://chaserobertson.github.io/posts/svm/"},"url":"https://chaserobertson.github.io/posts/svm/"}</script><title>Support Vector Machines | Chase Robertson</title><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="Chase Robertson"><meta name="application-name" content="Chase Robertson"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="stylesheet" href="/assets/lib/fonts/main.css"><link rel="stylesheet" href="/assets/lib/bootstrap-4.6.1/bootstrap.min.css"><link rel="stylesheet" href="/assets/lib/fontawesome-free-5.15.4/css/all.min.css"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="/assets/lib/bootstrap-toc-1.0.1/bootstrap-toc.min.css"><link rel="stylesheet" href="/assets/lib/magnific-popup-1.1.0/magnific-popup.css"> <script src="/assets/lib/jquery-3.6.0/jquery.min.js"></script> <script type="text/javascript"> class ModeToggle { static get MODE_KEY() { return "mode"; } static get MODE_ATTR() { return "data-mode"; } static get DARK_MODE() { return "dark"; } static get LIGHT_MODE() { return "light"; } static get ID() { return "mode-toggle"; } constructor() { if (this.hasMode) { if (this.isDarkMode) { if (!this.isSysDarkPrefer) { this.setDark(); } } else { if (this.isSysDarkPrefer) { this.setLight(); } } } let self = this; /* always follow the system prefers */ this.sysDarkPrefers.addEventListener("change", () => { if (self.hasMode) { if (self.isDarkMode) { if (!self.isSysDarkPrefer) { self.setDark(); } } else { if (self.isSysDarkPrefer) { self.setLight(); } } self.clearMode(); } self.notify(); }); } /* constructor() */ get sysDarkPrefers() { return window.matchMedia("(prefers-color-scheme: dark)"); } get isSysDarkPrefer() { return this.sysDarkPrefers.matches; } get isDarkMode() { return this.mode === ModeToggle.DARK_MODE; } get isLightMode() { return this.mode === ModeToggle.LIGHT_MODE; } get hasMode() { return this.mode != null; } get mode() { return sessionStorage.getItem(ModeToggle.MODE_KEY); } /* get the current mode on screen */ get modeStatus() { if (this.isDarkMode || (!this.hasMode && this.isSysDarkPrefer)) { return ModeToggle.DARK_MODE; } else { return ModeToggle.LIGHT_MODE; } } setDark() { $('html').attr(ModeToggle.MODE_ATTR, ModeToggle.DARK_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); } setLight() { $('html').attr(ModeToggle.MODE_ATTR, ModeToggle.LIGHT_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); } clearMode() { $('html').removeAttr(ModeToggle.MODE_ATTR); sessionStorage.removeItem(ModeToggle.MODE_KEY); } /* Notify another plugins that the theme mode has changed */ notify() { window.postMessage({ direction: ModeToggle.ID, message: this.modeStatus }, "*"); } } /* ModeToggle */ const toggle = new ModeToggle(); function flipMode() { if (toggle.hasMode) { if (toggle.isSysDarkPrefer) { if (toggle.isLightMode) { toggle.clearMode(); } else { toggle.setLight(); } } else { if (toggle.isDarkMode) { toggle.clearMode(); } else { toggle.setDark(); } } } else { if (toggle.isSysDarkPrefer) { toggle.setLight(); } else { toggle.setDark(); } } toggle.notify(); } /* flipMode() */ </script><body data-spy="scroll" data-target="#toc" data-topbar-visible="true"><div id="sidebar" class="d-flex flex-column align-items-end"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/" class="mx-auto"> <img src="/assets/img/me.png" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title mt-3"> <a href="/">Chase Robertson</a></div><div class="site-subtitle font-italic">Data Scientist</div></div><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/Thesis/" class="nav-link"> <i class="fa-fw fas fa-bolt ml-xl-3 mr-xl-3 unloaded"></i> <span>THESIS</span> </a><li class="nav-item"> <a href="/Resume/" class="nav-link"> <i class="fa-fw fas fa-user ml-xl-3 mr-xl-3 unloaded"></i> <span>RESUME</span> </a><li class="nav-item"> <a href="/CV/" class="nav-link"> <i class="fa-fw fas fa-address-card ml-xl-3 mr-xl-3 unloaded"></i> <span>CV</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fas fa-info-circle ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a><li class="nav-item"> <a href="/certifications/" class="nav-link"> <i class="fa-fw fas fa-certificate ml-xl-3 mr-xl-3 unloaded"></i> <span>CERTIFICATIONS</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tag ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center align-items-center"> <button class="mode-toggle btn" aria-label="Switch Mode"> <i class="fas fa-adjust"></i> </button> <span class="icon-border"></span> <a href="https://github.com/chaserobertson" aria-label="github" target="_blank" rel="noopener"> <i class="fab fa-github"></i> </a> <a href="https://twitter.com/chase__rob" aria-label="twitter" target="_blank" rel="noopener"> <i class="fab fa-twitter"></i> </a> <a href=" javascript:location.href = 'mailto:' + ['chaserobertson208','gmail.com'].join('@')" aria-label="email" > <i class="fas fa-envelope"></i> </a> <a href="https://linkedin.com/in/chase-robertson" aria-label="linkedin" target="_blank" rel="noopener"> <i class="fab fa-linkedin"></i> </a></div></div><div id="topbar-wrapper" class="row justify-content-center"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/"> Home </a> </span> <span>Support Vector Machines</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="Search..."> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper"><div id="main"><div class="row"><div id="core-wrapper" class="col-12 col-lg-11 col-xl-8"><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"> <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script><h1 data-toc-skip>Support Vector Machines</h1><div class="post-meta text-muted"> <span> Posted <em class="" data-ts="1655640000" data-df="ll" data-toggle="tooltip" data-placement="bottom"> 20 Jun 2022 </em> </span><div class="d-flex justify-content-between"> <span> By <em> <a href="https://twitter.com/chase__rob">Chase Robertson</a> </em> </span><div> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="1397 words"> <em>7 min</em> read</span></div></div></div><div class="post-content"><p>In this assignment for a machine learning course, I generate synthetic data and explore how the underlying patterns affect SVM tuning parameters.</p><h2 id="ds1"><span class="mr-2"><code class="language-plaintext highlighter-rouge"><span class="mr-2">DS1</code></span><a href="#ds1" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><ol><li>Design a new dataset <code class="language-plaintext highlighter-rouge">DS1</code> with at least 50 points, for which the selection of the complexity parameter C in a linear SVM makes a difference.</ol><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
</pre><td class="rouge-code"><pre><span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="p">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s">'ignore'</span><span class="p">)</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_classification</span><span class="p">,</span> <span class="n">make_blobs</span>

<span class="c1"># generate reproducible dataset
</span><span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">12345</span><span class="p">)</span>
<span class="n">N_SAMPLES</span> <span class="o">=</span> <span class="mi">60</span>

<span class="c1"># vertical cluster (dark, class 0)
</span><span class="n">x1</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">normal</span><span class="p">(</span><span class="n">scale</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
<span class="n">y1</span> <span class="o">=</span> <span class="n">x1</span><span class="o">-</span><span class="n">np</span><span class="p">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">30</span><span class="p">)</span>

<span class="c1"># horizontal cluster (light, class 1)
</span><span class="n">x2</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">30</span><span class="p">)</span>
<span class="n">y2</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">normal</span><span class="p">(</span><span class="n">scale</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>

<span class="c1"># combine classes into one dataset
</span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">stack</span><span class="p">([</span><span class="n">np</span><span class="p">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">x1</span><span class="p">,</span><span class="n">x2</span><span class="p">]),</span> <span class="n">np</span><span class="p">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">y1</span><span class="p">,</span><span class="n">y2</span><span class="p">])]).</span><span class="n">T</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">x1</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="mi">1</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">x2</span><span class="p">])</span>

<span class="c1"># plot data
</span><span class="n">plt</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">X</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">y</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># save to csv file
</span><span class="n">DS_array</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">column_stack</span><span class="p">([</span><span class="n">X</span><span class="p">.</span><span class="nb">round</span><span class="p">(</span><span class="mi">6</span><span class="p">),</span> <span class="n">y</span><span class="p">])</span>
<span class="n">DS</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">DS_array</span><span class="p">).</span><span class="n">astype</span><span class="p">({</span><span class="mi">2</span><span class="p">:</span><span class="s">'int'</span><span class="p">})</span>
<span class="n">DS</span><span class="p">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s">'D1.csv'</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
</pre></table></code></div></div><p><img data-src="../../assets/img/svm/output_1_0.png" alt="png" data-proofer-ignore></p><ol><li>Load the data set <code class="language-plaintext highlighter-rouge">DS1</code>, train an SVM with a linear kernel on the full data set, and plot the data set with the decision boundary.</ol><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
</pre><td class="rouge-code"><pre><span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVC</span>


<span class="c1"># fit, plot, and return SVM with specified kw parameters
</span><span class="k">def</span> <span class="nf">fit_and_plot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="c1"># create an x,y mesh to predict and plot
</span>    <span class="n">x_min</span><span class="p">,</span> <span class="n">y_min</span> <span class="o">=</span> <span class="n">X</span><span class="p">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">0</span><span class="p">:</span><span class="mi">2</span><span class="p">].</span><span class="nb">min</span><span class="p">()</span>
    <span class="n">x_max</span><span class="p">,</span> <span class="n">y_max</span> <span class="o">=</span> <span class="n">X</span><span class="p">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">0</span><span class="p">:</span><span class="mi">2</span><span class="p">].</span><span class="nb">max</span><span class="p">()</span>
    <span class="n">grain</span> <span class="o">=</span> <span class="p">(</span><span class="n">x_max</span> <span class="o">-</span> <span class="n">x_min</span><span class="p">)</span> <span class="o">/</span> <span class="mi">100</span>
    <span class="n">margin</span> <span class="o">=</span> <span class="n">grain</span> <span class="o">*</span> <span class="mi">10</span>
    <span class="n">xx</span><span class="p">,</span> <span class="n">yy</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="n">x_min</span><span class="o">-</span><span class="n">margin</span><span class="p">,</span> <span class="n">x_max</span><span class="o">+</span><span class="n">margin</span><span class="p">,</span> <span class="n">grain</span><span class="p">),</span>
                         <span class="n">np</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="n">y_min</span><span class="o">-</span><span class="n">margin</span><span class="p">,</span> <span class="n">y_max</span><span class="o">+</span><span class="n">margin</span><span class="p">,</span> <span class="n">grain</span><span class="p">))</span>
    
    <span class="c1"># fit linear SVM classifier and predict z
</span>    <span class="n">svc</span> <span class="o">=</span> <span class="n">SVC</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">).</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="n">Z</span> <span class="o">=</span> <span class="n">svc</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">c_</span><span class="p">[</span><span class="n">xx</span><span class="p">.</span><span class="n">ravel</span><span class="p">(),</span> <span class="n">yy</span><span class="p">.</span><span class="n">ravel</span><span class="p">()])</span>
    <span class="n">zz</span> <span class="o">=</span> <span class="n">Z</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">xx</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>

    <span class="c1"># scatter plot and decision boundary
</span>    <span class="n">plt</span><span class="p">.</span><span class="n">contourf</span><span class="p">(</span><span class="n">xx</span><span class="p">,</span> <span class="n">yy</span><span class="p">,</span> <span class="n">zz</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">plt</span><span class="p">.</span><span class="n">cm</span><span class="p">.</span><span class="n">coolwarm</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">X</span><span class="p">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">X</span><span class="p">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">y</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
    
    <span class="k">return</span> <span class="n">svc</span>


<span class="c1"># load custom dataset from save file
</span><span class="n">DS1</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">'D1.csv'</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
<span class="n">X1</span> <span class="o">=</span> <span class="n">DS1</span><span class="p">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">:</span><span class="mi">2</span><span class="p">]</span>
<span class="n">y1</span> <span class="o">=</span> <span class="n">DS1</span><span class="p">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">]</span>
<span class="n">N_SAMPLES1</span> <span class="o">=</span> <span class="n">DS1</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

<span class="n">svc1</span> <span class="o">=</span> <span class="n">fit_and_plot</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span> <span class="n">y1</span><span class="p">,</span> <span class="n">kernel</span><span class="o">=</span><span class="s">'linear'</span><span class="p">)</span>
</pre></table></code></div></div><p><img data-src="../../assets/img/svm/output_3_0.png" alt="png" data-proofer-ignore></p><ol><li>Carry out a leave-1-out cross-validation with an SVM on the dataset. Report the performance on training and test set.</ol><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
</pre><td class="rouge-code"><pre><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">LeaveOneOut</span><span class="p">,</span> <span class="n">cross_validate</span>

<span class="c1"># pretty-print scores from a cross-validation instance
</span><span class="k">def</span> <span class="nf">print_scores</span><span class="p">(</span><span class="n">cv</span><span class="p">):</span>
    <span class="c1"># print both training and test scores
</span>    <span class="k">for</span> <span class="n">score</span> <span class="ow">in</span> <span class="p">[</span><span class="s">'train_score'</span><span class="p">,</span> <span class="s">'test_score'</span><span class="p">]:</span>
        <span class="n">u</span><span class="p">,</span> <span class="n">c</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">unique</span><span class="p">(</span><span class="n">cv</span><span class="p">[</span><span class="n">score</span><span class="p">],</span> <span class="n">return_counts</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="n">u</span> <span class="o">=</span> <span class="n">u</span><span class="p">.</span><span class="nb">round</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
        <span class="n">di</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">c</span><span class="p">)).</span><span class="n">items</span><span class="p">()</span>
        <span class="n">n</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">([</span><span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span><span class="n">v</span> <span class="ow">in</span> <span class="n">di</span><span class="p">])</span>
        
        <span class="c1"># show unique scores and n times those scores were achieved
</span>        <span class="k">print</span><span class="p">(</span><span class="s">'CV '</span><span class="p">,</span> <span class="n">score</span><span class="p">,</span> <span class="s">'s: '</span><span class="p">,</span> 
              <span class="s">', '</span><span class="p">.</span><span class="n">join</span><span class="p">([</span><span class="s">'*'</span><span class="p">.</span><span class="n">join</span><span class="p">([</span><span class="nb">str</span><span class="p">(</span><span class="n">k</span><span class="p">),</span><span class="nb">str</span><span class="p">(</span><span class="n">v</span><span class="p">)])</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span><span class="n">v</span> <span class="ow">in</span> <span class="n">di</span><span class="p">]),</span> 
              <span class="n">sep</span><span class="o">=</span><span class="s">''</span><span class="p">)</span>
        
        <span class="c1"># show weighted mean of scores
</span>        <span class="k">print</span><span class="p">(</span><span class="s">'Mean CV'</span><span class="p">,</span> <span class="n">score</span><span class="p">,</span> 
              <span class="nb">round</span><span class="p">(</span><span class="nb">sum</span><span class="p">([</span><span class="n">k</span><span class="o">*</span><span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span><span class="n">v</span> <span class="ow">in</span> <span class="n">di</span><span class="p">])</span><span class="o">/</span><span class="n">n</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="s">'</span><span class="se">\n</span><span class="s">'</span><span class="p">)</span>

        
<span class="c1"># print scores of linear SVM with default C
</span><span class="n">loo</span> <span class="o">=</span> <span class="n">LeaveOneOut</span><span class="p">()</span>
<span class="n">cv1</span> <span class="o">=</span> <span class="n">cross_validate</span><span class="p">(</span><span class="n">svc1</span><span class="p">,</span> <span class="n">X1</span><span class="p">,</span> <span class="n">y1</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">loo</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span> <span class="n">y1</span><span class="p">),</span> 
                     <span class="n">return_train_score</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">print_scores</span><span class="p">(</span><span class="n">cv1</span><span class="p">)</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span data-label-text="Plaintext"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre><td class="rouge-code"><pre>CV train_scores: 0.814*3, 0.831*47, 0.847*10
Mean CV train_score 0.83282 

CV test_scores: 0.0*11, 1.0*49
Mean CV test_score 0.81667 
</pre></table></code></div></div><ol><li>Improve the SVM by changing C. Plot the data set and resulting decision boundary, give the performance.</ol><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre><td class="rouge-code"><pre><span class="c1"># fit, plot and print scores of linear SVM with increased C
</span><span class="n">svc1</span> <span class="o">=</span> <span class="n">fit_and_plot</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span> <span class="n">y1</span><span class="p">,</span> <span class="n">kernel</span><span class="o">=</span><span class="s">'linear'</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
<span class="n">cv1</span> <span class="o">=</span> <span class="n">cross_validate</span><span class="p">(</span><span class="n">svc1</span><span class="p">,</span> <span class="n">X1</span><span class="p">,</span> <span class="n">y1</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">loo</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span> <span class="n">y1</span><span class="p">),</span> 
                     <span class="n">return_train_score</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">print_scores</span><span class="p">(</span><span class="n">cv1</span><span class="p">)</span>
</pre></table></code></div></div><p><img data-src="../../assets/img/svm/output_7_0.png" alt="png" data-proofer-ignore></p><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span data-label-text="Plaintext"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre><td class="rouge-code"><pre>CV train_scores: 0.864*9, 0.881*47, 0.898*4
Mean CV train_score 0.87958 

CV test_scores: 0.0*8, 1.0*52
Mean CV test_score 0.86667 
</pre></table></code></div></div><ol><li>Discuss what C does and how it improved the SVM in this case.</ol><p>The complexity parameter C tunes the trade-off between hyperplane margin width and training error. A higher value for C penalises more heavily on misclassified points which are far from their correct margin boundary, thus encouraging a tighter fit to the training data. Likewise, a lower C penalises the same points lightly, giving the model less complexity and a decision boundary less biased to the training data.</p><p>In this case, increasing C further penalised the misclassification of those few points near the decision boundary. By penalising those misclassifications, the SVM algorithm chose a boundary which was more closely fit to the data.</p><h2 id="ds2"><span class="mr-2"><code class="language-plaintext highlighter-rouge"><span class="mr-2">DS2</code></span><a href="#ds2" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><ol><li>Repeat step 1.2 and 1.3 with <code class="language-plaintext highlighter-rouge">DS2</code>, justifying any change to the cross validation technique or number of folds.</ol><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
</pre><td class="rouge-code"><pre><span class="c1"># load provided dataset from save file
</span><span class="n">DS2</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">'D2.csv'</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
<span class="n">X2</span> <span class="o">=</span> <span class="n">DS2</span><span class="p">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">:</span><span class="mi">2</span><span class="p">]</span>
<span class="n">y2</span> <span class="o">=</span> <span class="n">DS2</span><span class="p">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">]</span>
<span class="n">N_SAMPLES2</span> <span class="o">=</span> <span class="n">DS2</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

<span class="c1"># C=10^6 to enable linear SVM to find a sufficient decision boundary
</span><span class="n">svc2linear</span> <span class="o">=</span> <span class="n">fit_and_plot</span><span class="p">(</span><span class="n">X2</span><span class="p">,</span> <span class="n">y2</span><span class="p">,</span> <span class="n">kernel</span><span class="o">=</span><span class="s">'linear'</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span><span class="mi">10</span><span class="o">**</span><span class="mi">6</span><span class="p">)</span>
</pre></table></code></div></div><p><img data-src="../../assets/img/svm/output_10_0.png" alt="png" data-proofer-ignore></p><p>The linear kernel was not able to select a decision boundary for this data with any lower complexity parameters attempted. But with a complexity parameter so high, conducting a full Leave-One-Out cross-validation became too computationally expensive, so I am switching here to a 5-fold cross-validation.</p><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
</pre><td class="rouge-code"><pre><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">KFold</span>

<span class="c1"># print training and test scores from CV
</span><span class="n">kf</span> <span class="o">=</span> <span class="n">KFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">cv2</span> <span class="o">=</span> <span class="n">cross_validate</span><span class="p">(</span><span class="n">svc2linear</span><span class="p">,</span> <span class="n">X2</span><span class="p">,</span> <span class="n">y2</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">kf</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="n">X2</span><span class="p">,</span> <span class="n">y2</span><span class="p">),</span> 
                     <span class="n">return_train_score</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">print_scores</span><span class="p">(</span><span class="n">cv2</span><span class="p">)</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span data-label-text="Plaintext"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre><td class="rouge-code"><pre>CV train_scores: 0.55*1, 0.555*1, 0.568*1, 0.582*1, 0.59*1
Mean CV train_score 0.569 

CV test_scores: 0.44*1, 0.49*1, 0.51*1, 0.54*2
Mean CV test_score 0.504 
</pre></table></code></div></div><ol><li>Pick a kernel which will improve the SVM, plot the data set and resulting decision boundary, give the performance.</ol><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre><td class="rouge-code"><pre><span class="c1"># fit, plot and print cv scores of SVM with RBF kernel
</span><span class="n">svc2rbf</span> <span class="o">=</span> <span class="n">fit_and_plot</span><span class="p">(</span><span class="n">X2</span><span class="p">,</span> <span class="n">y2</span><span class="p">,</span> <span class="n">kernel</span><span class="o">=</span><span class="s">'rbf'</span><span class="p">)</span>
<span class="n">cv2</span> <span class="o">=</span> <span class="n">cross_validate</span><span class="p">(</span><span class="n">svc2rbf</span><span class="p">,</span> <span class="n">X2</span><span class="p">,</span> <span class="n">y2</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">loo</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">),</span> 
                     <span class="n">return_train_score</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">print_scores</span><span class="p">(</span><span class="n">cv2</span><span class="p">)</span>
</pre></table></code></div></div><p><img data-src="../../assets/img/svm/output_14_0.png" alt="png" data-proofer-ignore></p><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span data-label-text="Plaintext"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre><td class="rouge-code"><pre>CV train_scores: 0.847*4, 0.864*4, 0.881*35, 0.898*12, 0.915*5
Mean CV train_score 0.88383 

CV test_scores: 0.0*12, 1.0*48
Mean CV test_score 0.8 
</pre></table></code></div></div><ol><li>Discuss which kernel was chosen and why.</ol><p>I chose to use the Radial Basis kernel, because it is the latest-and-greatest standard kernel for non-linear tasks. This dataset is clearly one that requires nonlinear separation, which would be more difficult or impossible to achieve with polynomial or other kernels. RBF was able to efficiently find a reasonable decision boundary, even without tuning other hyperparameters like C.</p><h2 id="ds3"><span class="mr-2"><code class="language-plaintext highlighter-rouge"><span class="mr-2">DS3</code></span><a href="#ds3" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><ol><li>Repeat step 1.2 and 1.3 with <code class="language-plaintext highlighter-rouge">DS3</code>, again justifying any change to the cross validation technique or number of folds.</ol><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
</pre><td class="rouge-code"><pre><span class="c1"># load provided dataset from save file
</span><span class="n">DS3</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">'D3.csv'</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
<span class="n">X3</span> <span class="o">=</span> <span class="n">DS3</span><span class="p">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">:</span><span class="mi">2</span><span class="p">]</span>
<span class="n">y3</span> <span class="o">=</span> <span class="n">DS3</span><span class="p">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">]</span>
<span class="n">N_SAMPLES3</span> <span class="o">=</span> <span class="n">DS3</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

<span class="n">svc3</span> <span class="o">=</span> <span class="n">fit_and_plot</span><span class="p">(</span><span class="n">X3</span><span class="p">,</span> <span class="n">y3</span><span class="p">,</span> <span class="n">kernel</span><span class="o">=</span><span class="s">'linear'</span><span class="p">)</span>
</pre></table></code></div></div><p><img data-src="../../assets/img/svm/output_17_0.png" alt="png" data-proofer-ignore></p><p>This dataset is linearly separable without a high complexity parameter, so I am reverting back to leave-one-out CV to maximise insight into the modelâ€™s performance.</p><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre><td class="rouge-code"><pre><span class="n">cv3</span> <span class="o">=</span> <span class="n">cross_validate</span><span class="p">(</span><span class="n">svc3</span><span class="p">,</span> <span class="n">X3</span><span class="p">,</span> <span class="n">y3</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">loo</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span> <span class="n">y1</span><span class="p">),</span> 
                     <span class="n">return_train_score</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">print_scores</span><span class="p">(</span><span class="n">cv3</span><span class="p">)</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span data-label-text="Plaintext"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre><td class="rouge-code"><pre>CV train_scores: 0.898*54, 0.915*6
Mean CV train_score 0.8997 

CV test_scores: 0.0*6, 1.0*54
Mean CV test_score 0.9 
</pre></table></code></div></div><ol><li>Pick a kernel and 2 parameters and optimize, optimize the parameters, plot again the data set and decision boundary, and give the performance.</ol><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
</pre><td class="rouge-code"><pre><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">GridSearchCV</span>

<span class="n">params</span> <span class="o">=</span> <span class="p">{</span><span class="s">'kernel'</span><span class="p">:</span> <span class="p">[</span><span class="s">'sigmoid'</span><span class="p">],</span>
          <span class="s">'gamma'</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">20</span><span class="p">),</span>
          <span class="s">'coef0'</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">20</span><span class="p">),</span>
          <span class="s">'C'</span><span class="p">:</span> <span class="p">[</span><span class="mi">10</span><span class="o">**</span><span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">]]}</span>

<span class="n">grid_search</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">SVC</span><span class="p">(),</span> <span class="n">params</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="mi">2</span><span class="p">).</span><span class="n">fit</span><span class="p">(</span><span class="n">X3</span><span class="p">,</span><span class="n">y3</span><span class="p">)</span>
<span class="n">svc3sig</span> <span class="o">=</span> <span class="n">fit_and_plot</span><span class="p">(</span><span class="n">X3</span><span class="p">,</span> <span class="n">y3</span><span class="p">,</span> <span class="o">**</span><span class="n">grid_search</span><span class="p">.</span><span class="n">best_params_</span><span class="p">)</span>
<span class="n">grid_search</span><span class="p">.</span><span class="n">best_params_</span>
</pre></table></code></div></div><p><img data-src="../../assets/img/svm/output_21_1.png" alt="png" data-proofer-ignore></p><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span data-label-text="Plaintext"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre><td class="rouge-code"><pre>{'C': 10,
 'coef0': -3.4210526315789473,
 'gamma': 0.47368421052631576,
 'kernel': 'sigmoid'}
</pre></table></code></div></div><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre><td class="rouge-code"><pre><span class="n">cv3sig</span> <span class="o">=</span> <span class="n">cross_validate</span><span class="p">(</span><span class="n">svc3sig</span><span class="p">,</span> <span class="n">X3</span><span class="p">,</span> <span class="n">y3</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">loo</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="n">X3</span><span class="p">,</span> <span class="n">y3</span><span class="p">),</span> 
                        <span class="n">return_train_score</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">print_scores</span><span class="p">(</span><span class="n">cv3sig</span><span class="p">)</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span data-label-text="Plaintext"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre><td class="rouge-code"><pre>CV train_scores: 0.915*3, 0.95*2, 0.955*2, 0.96*129, 0.965*60, 0.97*4
Mean CV train_score 0.96087 

CV test_scores: 0.0*9, 1.0*191
Mean CV test_score 0.955 
</pre></table></code></div></div><ol><li>Discuss the results of the previous step.</ol><p>I chose the sigmoid kernel due to the near-linear separation between the two classes of this dataset. By tuning the <code class="language-plaintext highlighter-rouge">gamma</code> and <code class="language-plaintext highlighter-rouge">coef0</code> parameters of the sigmoid kernel, the near-linear decision boundary was able to squiggle into the small gaps between the two classes and improve the accuracy of the model.</p><p>However, even with the improvement in test accuracy, I would actually prefer to keep the linear model. The linear separation between classes is quite clear, and there was no difference between training and test accuracy of the linear model. With so few observations in the dataset, the accuracy improvement of the sigmoid model is likely to just be the result of overfit to noise. I think the linear model describes the data better, and would likely end up performing better on future data.</p></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/machine-learning/'>Machine Learning</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/python/" class="post-tag no-text-decoration" >python</a> <a href="/tags/sklearn/" class="post-tag no-text-decoration" >sklearn</a> <a href="/tags/machine-learning/" class="post-tag no-text-decoration" >machine-learning</a> <a href="/tags/support-vector-machine/" class="post-tag no-text-decoration" >support-vector-machine</a> <a href="/tags/synthetic-data/" class="post-tag no-text-decoration" >synthetic-data</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/"> CC BY 4.0 </a> by the author.</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=Support+Vector+Machines+-+Chase+Robertson&url=https%3A%2F%2Fchaserobertson.github.io%2Fposts%2Fsvm%2F" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=Support+Vector+Machines+-+Chase+Robertson&u=https%3A%2F%2Fchaserobertson.github.io%2Fposts%2Fsvm%2F" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://t.me/share/url?url=https%3A%2F%2Fchaserobertson.github.io%2Fposts%2Fsvm%2F&text=Support+Vector+Machines+-+Chase+Robertson" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <a href="https://www.linkedin.com/sharing/share-offsite/?url=https%3A%2F%2Fchaserobertson.github.io%2Fposts%2Fsvm%2F" data-toggle="tooltip" data-placement="top" title="Linkedin" target="_blank" rel="noopener" aria-label="Linkedin"> <i class="fa-fw fab fa-linkedin"></i> </a> <i id="copy-link" class="fa-fw fas fa-link small" data-toggle="tooltip" data-placement="top" title="Copy link" data-title-succeed="Link copied successfully!"> </i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted"><div class="access"><div id="access-lastmod" class="post"><div class="panel-heading">Recently Updated</div><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/posts/rgraphics/">Data Visualisation in base R</a></ul></div><div id="access-tags"><div class="panel-heading">Trending Tags</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/machine-learning/">machine-learning</a> <a class="post-tag" href="/tags/python/">python</a> <a class="post-tag" href="/tags/r/">R</a> <a class="post-tag" href="/tags/sklearn/">sklearn</a> <a class="post-tag" href="/tags/graphics/">graphics</a> <a class="post-tag" href="/tags/visualisation/">visualisation</a> <a class="post-tag" href="/tags/beautifulsoup/">beautifulsoup</a> <a class="post-tag" href="/tags/decision-tree/">decision-tree</a> <a class="post-tag" href="/tags/forecasting/">forecasting</a> <a class="post-tag" href="/tags/ggplot/">ggplot</a></div></div></div><script src="/assets/lib/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><div id="toc-wrapper" class="pl-0 pr-4 mb-5"><div class="panel-heading pl-3 pt-2 mb-2">Contents</div><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div class="col-12 col-lg-11 col-xl-8"><div id="tail-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/decision-tree/"><div class="card-body"> <em class="small" data-ts="1651752000" data-df="ll" > 6 May 2022 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Decision Tree Practice</h3><div class="text-muted small"><p> In this post, I compare 3 decision tree models pruned with different techniques. Analysis is conducted using 3 separate datasets to show how tree depth interacts with the dimensions of the dataset....</p></div></div></a></div><div class="card"> <a href="/posts/naive-bayes/"><div class="card-body"> <em class="small" data-ts="1651752000" data-df="ll" > 6 May 2022 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Naive Bayes Classification</h3><div class="text-muted small"><p> This post details the development process for my submission to the Point-of-Interest Categorization competition on Kaggle. Motivation In order to match the benchmark model performance initially, s...</p></div></div></a></div><div class="card"> <a href="/posts/ml-reflections/"><div class="card-body"> <em class="small" data-ts="1656504000" data-df="ll" > 30 Jun 2022 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Reflections on ML</h3><div class="text-muted small"><p> Latent thoughts and specific review regarding an introductory machine learning course taken at the University of Auckland. My Prior Since my first introduction to computers and computer science, ...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/posts/tenancies-amendment/" class="btn btn-outline-primary" prompt="Older"><p>NZ Housing Policy Exploration</p></a> <a href="/posts/ml-reflections/" class="btn btn-outline-primary" prompt="Newer"><p>Reflections on ML</p></a></div></div></div></div><footer class="d-flex w-100 justify-content-center"><div class="d-flex justify-content-between align-items-center text-muted"><div class="footer-left"><p class="mb-0"> Â© 2025 <a href="https://twitter.com/chase__rob">Chase Robertson</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span></p></div><div class="footer-right"><p class="mb-0"> Powered by <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> with <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a> theme.</p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><div id="access-tags"><div class="panel-heading">Trending Tags</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/machine-learning/">machine-learning</a> <a class="post-tag" href="/tags/python/">python</a> <a class="post-tag" href="/tags/r/">R</a> <a class="post-tag" href="/tags/sklearn/">sklearn</a> <a class="post-tag" href="/tags/graphics/">graphics</a> <a class="post-tag" href="/tags/visualisation/">visualisation</a> <a class="post-tag" href="/tags/beautifulsoup/">beautifulsoup</a> <a class="post-tag" href="/tags/decision-tree/">decision-tree</a> <a class="post-tag" href="/tags/forecasting/">forecasting</a> <a class="post-tag" href="/tags/ggplot/">ggplot</a></div></div></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <script src="/assets/lib/simple-jekyll-search-1.10.0/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No result founds.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script> <script src="/assets/lib/magnific-popup-1.1.0/jquery.magnific-popup.min.js"></script> <script src="/assets/lib/lozad-1.16.0/lozad.min.js"></script> <script src="/assets/lib/clipboard-2.0.9/clipboard.min.js"></script> <script src="/assets/lib/dayjs-1.10.7/dayjs.min.js"></script> <script src="/assets/lib/dayjs-1.10.7/locale/en.min.js"></script> <script src="/assets/lib/dayjs-1.10.7/plugin/relativeTime.min.js"></script> <script src="/assets/lib/dayjs-1.10.7/plugin/localizedFormat.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script src="/assets/lib/bootstrap-4.6.1/bootstrap.bundle.min.js"></script> <script defer src="/app.js"></script>
